{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set memory growth on all GPUs (if available)\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    \n",
    "    # Print the list of available GPUs\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    # Set memory growth on all GPUs\n",
    "    for i in range(num_gpus):\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8, i)  # Set 90% of GPU memory as usable\n",
    "        torch.cuda.set_device(i)\n",
    "        torch.cuda.empty_cache()  # Clear the GPU cache to avoid OOM\n",
    "        torch.backends.cudnn.benchmark = True  # Enable cuDNN benchmark for improved performance\n",
    "\n",
    "# Check for available GPUs\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(num_gpus):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)} with {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB total memory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "test_dir = '/home/ronie/Programs/Projects/2- Deep_Fake/Test'\n",
    "train_dir = '/home/ronie/Programs/Projects/2- Deep_Fake/Train'\n",
    "val_dir = '/home/ronie/Programs/Projects/2- Deep_Fake/Validation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "input_shape = (224, 224)\n",
    "batch_size = 32\n",
    "num_classes = 2  # Binary classification\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_shape),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(input_shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n",
    "    'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n",
    "    'test': datasets.ImageFolder(test_dir, data_transforms['test'])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=4),\n",
    "    'test': DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class DeepfakeDetectionModel(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes=2):\n",
    "        super(DeepfakeDetectionModel, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.residual_layers = self._make_layer(64, num_blocks)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def _make_layer(self, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        for _ in range(num_blocks):\n",
    "            layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.residual_layers(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Parameters\n",
    "input_shape = (3, 224, 224)  # Example input shape for image data\n",
    "num_classes = 2  # Binary classification for deepfake detection\n",
    "num_residual_blocks = 30\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Build and compile the model\n",
    "model = DeepfakeDetectionModel(num_blocks=num_residual_blocks, num_classes=num_classes).to(device)\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "print(model)\n",
    "\n",
    "# Freeze all layers except the last one\n",
    "for name, param in model.named_parameters():\n",
    "    if 'fc' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Set up the optimizer and loss function\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Define the ResNet model\n",
    "def build_resnet(num_classes):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "model = build_resnet(num_classes).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for tracking max validation accuracy\n",
    "class MaxValidationAccuracyCallback:\n",
    "    def __init__(self):\n",
    "        self.max_val_acc = 0\n",
    "\n",
    "    def __call__(self, val_acc):\n",
    "        if val_acc > self.max_val_acc:\n",
    "            self.max_val_acc = val_acc\n",
    "        print(f\"Max validation accuracy so far is {self.max_val_acc * 100:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Callback for tracking max test accuracy\n",
    "class MaxTestAccuracyCallback:\n",
    "    def __init__(self):\n",
    "        self.max_test_acc = 0\n",
    "\n",
    "    def __call__(self, test_acc):\n",
    "        if test_acc > self.max_test_acc:\n",
    "            self.max_test_acc = test_acc\n",
    "        print(f\"Max test accuracy so far is {self.max_test_acc * 100:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "max_val_acc_callback = MaxValidationAccuracyCallback()\n",
    "max_test_acc_callback = MaxTestAccuracyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, criterion, optimizer, num_epochs=epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    history_acc = []\n",
    "    history_val_acc = []\n",
    "    history_loss = []\n",
    "    history_val_loss = []\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            \n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # Callback for max validation accuracy\n",
    "            if phase == 'val':\n",
    "                max_val_acc_callback(epoch_acc.item())\n",
    "                     \n",
    "            \n",
    "\n",
    "\n",
    "            # Store the metrics\n",
    "            if phase == 'train':\n",
    "                history_acc.append(epoch_acc.cpu().numpy())\n",
    "                history_loss.append(epoch_loss)\n",
    "            else:\n",
    "                history_val_acc.append(epoch_acc.cpu().numpy())\n",
    "                history_val_loss.append(epoch_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history_acc, history_val_acc, history_loss, history_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model, history_acc, history_val_acc, history_loss, history_val_loss = train_model(model, criterion, optimizer, num_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    print(f'Test Loss: {epoch_loss:.4f} Test Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    max_test_acc_callback(epoch_acc.item())\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "test_loss, test_acc = evaluate_model(model, dataloaders['test'], criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for prediction\n",
    "def predict_image(image_path, model):\n",
    "    transform = data_transforms['test']\n",
    "    img = Image.open(image_path)\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        return 'REAL IMAGE' if preds.item() == 1 else 'FAKE IMAGE'\n",
    "\n",
    "image_path = '/home/ronie/Programs/Projects/2- Deep_Fake/Test/Fake/fake_5448.jpg'\n",
    "print(predict_image(image_path, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training history\n",
    "# Note: In this example, we haven't stored the history during training as in TensorFlow.\n",
    "# For simplicity, we'll just demonstrate plotting dummy data here.\n",
    "\n",
    "plt.plot(history_acc, label='Train Accuracy')\n",
    "plt.plot(history_val_acc, label='Validation Accuracy')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history_loss, label='Train Loss')\n",
    "plt.plot(history_val_loss, label='Validation Loss')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import torch\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Create a batch of dummy inputs\n",
    "batch_size = 1  # or any batch size you need\n",
    "dummy_input = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Create the graph for visualization\n",
    "graph = make_dot(output, params=dict(model.named_parameters()))\n",
    "\n",
    "# Save the graph as a PDF\n",
    "graph.render(\"model_architecture\", format=\"pdf\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
